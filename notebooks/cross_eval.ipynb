{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bad9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from flipper_training.experiments.ppo.eval import get_eval_rollout, log_from_eval_rollout, PPOExperimentConfig\n",
    "import contextlib\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0facaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../cross_eval_configs/cross_eval_seeds.txt\") as f:\n",
    "    seeds = list(map(int, f.readlines()))\n",
    "\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"final_trunk_thesis_training_42_2025-05-09_21-01-13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fef2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = Path(\"../runs/ppo\") / run\n",
    "weights_step = \"final\"\n",
    "train_config = OmegaConf.load(run_path / \"config.yaml\")\n",
    "train_config.policy_weights_path = run_path / \"weights\" / f\"policy_{weights_step}.pth\"\n",
    "train_config.vecnorm_weights_path = run_path / \"weights\" / f\"vecnorm_{weights_step}.pth\"\n",
    "\n",
    "assert train_config.policy_weights_path.exists(), f\"Policy weights not found at {train_config.policy_weights_path}\"\n",
    "assert train_config.vecnorm_weights_path.exists(), f\"Vecnorm weights not found at {train_config.vecnorm_weights_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config[\"num_robots\"] = 16\n",
    "train_config[\"objective_opts\"][\"cache_size\"] = 10\n",
    "train_config[\"max_eval_steps\"] = 1000\n",
    "train_config = PPOExperimentConfig(**train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_configs_base = Path(\"../cross_eval_configs\")\n",
    "eval_results_base = Path(\"../cross_eval_results\") / run\n",
    "eval_results_base.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "devnull_handle = open(os.devnull, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa748c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training environment\n",
    "if not (eval_results_base / \"training.pkl\").exists():\n",
    "    print(\"Evaluating training environment\")\n",
    "    results = []\n",
    "    for seed in tqdm(seeds, desc=\"Training environment\"):\n",
    "        tqdm.write(f\"Evaluating seed {seed}\")\n",
    "        train_config.seed = seed\n",
    "        with contextlib.redirect_stdout(devnull_handle):\n",
    "            with contextlib.redirect_stderr(devnull_handle):\n",
    "                _, eval_rollout = get_eval_rollout(train_config)\n",
    "        log = log_from_eval_rollout(eval_rollout)\n",
    "        results.append(log)\n",
    "    with open(eval_results_base / \"training.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "for test_config_path in test_configs_base.glob(\"*.yaml\"):\n",
    "    if (eval_results_base / test_config_path.stem).exists():\n",
    "        print(f\"Skipping {test_config_path.stem} as it already exists\")\n",
    "        continue\n",
    "    print(f\"Evaluating {test_config_path.stem}\")\n",
    "    test_config = OmegaConf.load(test_config_path)\n",
    "    train_config.objective_opts = test_config[\"objective_opts\"]\n",
    "    train_config.heightmap_gen_opts = test_config[\"heightmap_gen_opts\"]\n",
    "    train_config.objective = test_config[\"objective\"]\n",
    "    train_config.heightmap_gen = test_config[\"heightmap_gen\"]\n",
    "    results = []\n",
    "    for seed in tqdm(seeds, desc=f\"Evaluating {test_config_path.stem}\"):\n",
    "        train_config.seed = seed\n",
    "        with contextlib.redirect_stdout(devnull_handle):\n",
    "            with contextlib.redirect_stderr(devnull_handle):\n",
    "                _, eval_rollout = get_eval_rollout(train_config)\n",
    "        log = log_from_eval_rollout(eval_rollout)\n",
    "        results.append(log)\n",
    "\n",
    "    with open(eval_results_base / f\"{test_config_path.stem}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf79f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for f in eval_results_base.glob(\"*.pkl\"):\n",
    "    with open(f, \"rb\") as r:\n",
    "        results = pickle.load(r)\n",
    "    results_dict[f.stem] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672feb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dicts_to_dict_of_lists(list_of_dicts):\n",
    "    \"\"\"\n",
    "    Convert a list of dictionaries to a dictionary of lists.\n",
    "    \"\"\"\n",
    "    dict_of_lists = {}\n",
    "    for d in list_of_dicts:\n",
    "        for k, v in d.items():\n",
    "            if k not in dict_of_lists:\n",
    "                dict_of_lists[k] = []\n",
    "            dict_of_lists[k].append(v)\n",
    "    return dict_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f671e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_transposed = {k: list_of_dicts_to_dict_of_lists(v) for k, v in results_dict.items()}\n",
    "results_transposed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77877ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "key2name = {\n",
    "    \"training\": \"Training Dist\",\n",
    "    \"stairs_hard\": \"Stairs-Hard\",\n",
    "    \"stairs_easy\": \"Stairs-Easy\",\n",
    "    \"barrier_easy\": \"Barrier-Easy\",\n",
    "    \"barrier_hard\": \"Barrier-Hard\",\n",
    "    \"gauss_coarse_hard\": \"Gauss-Coarse-Hard\",\n",
    "    \"gauss_fine_easy\": \"Gauss-Fine-Easy\",\n",
    "    \"gauss_fine_hard\": \"Gauss-Fine-Hard\",\n",
    "    \"gauss_coarse_easy\": \"Gauss-Coarse-Easy\",\n",
    "    \"trunk_easy\": \"Trunk-Easy\",\n",
    "    \"trunk_hard\": \"Trunk-Hard\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "# matplotlib.rcParams[\"text.usetex\"] = True\n",
    "\n",
    "# Separate keys for easy/training and hard/training\n",
    "easy_keys = [k for k in results_transposed if \"easy\" in k or \"training\" in k]\n",
    "hard_keys = [k for k in results_transposed if \"hard\" in k or \"training\" in k]\n",
    "\n",
    "# Plot for easy + training\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12), dpi=200)\n",
    "ax.set_ylabel(\"Success Rate\", fontsize=24, labelpad=12)\n",
    "ax.set_ylim(0, 1)\n",
    "green_color = \"#a8e6a3\"\n",
    "line_color = \"black\"\n",
    "for i, k in enumerate(easy_keys):\n",
    "    v = results_transposed[k]\n",
    "    pct_succeeded = v[\"eval/pct_succeeded\"]\n",
    "    ax.boxplot(\n",
    "        pct_succeeded,\n",
    "        positions=[i],\n",
    "        widths=0.3,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor=green_color, color=line_color),\n",
    "        medianprops=dict(color=line_color),\n",
    "        meanprops=dict(markerfacecolor=\"#ff4081\", markeredgecolor=\"black\", markersize=20),\n",
    "        capprops=dict(color=line_color),\n",
    "        whiskerprops=dict(color=line_color),\n",
    "        showmeans=True,\n",
    "    )\n",
    "ax.set_xticks(range(len(easy_keys)))\n",
    "ax.set_xticklabels([key2name.get(k.split(\".\")[0], k.split(\".\")[0]) for k in easy_keys], rotation=45, fontsize=20)\n",
    "ax.tick_params(axis=\"y\", labelsize=20)\n",
    "ax.set_title(\"Cross Evaluation Results\", fontsize=22, pad=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot for hard + training\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12), dpi=200)\n",
    "ax.set_ylabel(\"Success Rate\", fontsize=24, labelpad=12)\n",
    "ax.set_ylim(0, 1)\n",
    "for i, k in enumerate(hard_keys):\n",
    "    v = results_transposed[k]\n",
    "    pct_succeeded = v[\"eval/pct_succeeded\"]\n",
    "    ax.boxplot(\n",
    "        pct_succeeded,\n",
    "        positions=[i],\n",
    "        widths=0.3,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor=green_color, color=line_color),\n",
    "        medianprops=dict(color=line_color),\n",
    "        meanprops=dict(markerfacecolor=\"#ff4081\", markeredgecolor=\"black\", markersize=20),\n",
    "        capprops=dict(color=line_color),\n",
    "        whiskerprops=dict(color=line_color),\n",
    "        showmeans=True,\n",
    "    )\n",
    "ax.set_xticks(range(len(hard_keys)))\n",
    "ax.set_xticklabels([key2name.get(k.split(\".\")[0], k.split(\".\")[0]) for k in hard_keys], rotation=45, fontsize=20)\n",
    "ax.tick_params(axis=\"y\", labelsize=20)\n",
    "ax.set_title(\"Cross Evaluation Results\", fontsize=22, pad=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3829e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"text.usetex\"] = True\n",
    "\n",
    "# Separate keys for easy/training and hard/training\n",
    "easy_keys = [k for k in results_transposed if \"easy\" in k or \"training\" in k]\n",
    "hard_keys = [k for k in results_transposed if \"hard\" in k or \"training\" in k]\n",
    "\n",
    "# Plot for easy + training\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12), dpi=200)\n",
    "ax.set_ylabel(\"Failure Rate\", fontsize=24, labelpad=12)\n",
    "ax.set_ylim(0, 1)\n",
    "red_color = \"#ff8a80\"\n",
    "line_color = \"black\"\n",
    "for i, k in enumerate(easy_keys):\n",
    "    v = results_transposed[k]\n",
    "    pct_failed = v[\"eval/pct_failed\"]\n",
    "    ax.boxplot(\n",
    "        pct_failed,\n",
    "        positions=[i],\n",
    "        widths=0.3,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor=red_color, color=line_color),\n",
    "        medianprops=dict(color=line_color),\n",
    "        meanprops=dict(markerfacecolor=\"#a8e6a3\", markeredgecolor=\"black\", markersize=20),\n",
    "        capprops=dict(color=line_color),\n",
    "        whiskerprops=dict(color=line_color),\n",
    "        showmeans=True,\n",
    "    )\n",
    "ax.set_xticks(range(len(easy_keys)))\n",
    "ax.set_xticklabels([key2name.get(k.split(\".\")[0], k.split(\".\")[0]) for k in easy_keys], rotation=45, fontsize=20)\n",
    "ax.tick_params(axis=\"y\", labelsize=20)\n",
    "ax.set_title(\"Cross Evaluation Results\", fontsize=22, pad=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot for hard + training\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12), dpi=200)\n",
    "ax.set_ylabel(\"Failure Rate\", fontsize=24, labelpad=12)\n",
    "ax.set_ylim(0, 1)\n",
    "for i, k in enumerate(hard_keys):\n",
    "    v = results_transposed[k]\n",
    "    pct_failed = v[\"eval/pct_failed\"]\n",
    "    ax.boxplot(\n",
    "        pct_failed,\n",
    "        positions=[i],\n",
    "        widths=0.3,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor=red_color, color=line_color),\n",
    "        medianprops=dict(color=line_color),\n",
    "        meanprops=dict(markerfacecolor=\"#a8e6a3\", markeredgecolor=\"black\", markersize=20),\n",
    "        capprops=dict(color=line_color),\n",
    "        whiskerprops=dict(color=line_color),\n",
    "        showmeans=True,\n",
    "    )\n",
    "ax.set_xticks(range(len(hard_keys)))\n",
    "ax.set_xticklabels([key2name.get(k.split(\".\")[0], k.split(\".\")[0]) for k in hard_keys], rotation=45, fontsize=20)\n",
    "ax.tick_params(axis=\"y\", labelsize=20)\n",
    "ax.set_title(\"Cross Evaluation Results\", fontsize=22, pad=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
