{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e989e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams[\"text.usetex\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_path = Path(\"../runs/ppo\")\n",
    "run_basename = \"final_coarse_gaussian_terrain_thesis_\"\n",
    "date = \"2025-05-12\"\n",
    "all_runs = list(runs_path.glob(f\"{run_basename}*{date}*\"))\n",
    "all_runs.sort()\n",
    "print(all_runs)\n",
    "best_run = \"final_coarse_gaussian_terrain_thesis_98_2025-05-12_12-07-12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frames, eval_frames = [], []\n",
    "best_train, best_eval = None, None\n",
    "for run in all_runs:\n",
    "    train_csv = run / \"train.csv\"\n",
    "    eval_csv = run / \"eval.csv\"\n",
    "    if not train_csv.exists() or not eval_csv.exists():\n",
    "        print(f\"Missing {train_csv} or {eval_csv}\")\n",
    "        continue\n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    eval_df = pd.read_csv(eval_csv)\n",
    "    train_frames.append(train_df)\n",
    "    eval_frames.append(eval_df)\n",
    "    if run.name == best_run:\n",
    "        best_train = train_df\n",
    "        best_eval = eval_df\n",
    "\n",
    "# concatenate all dataframes along index\n",
    "train_df = pd.concat(train_frames)\n",
    "eval_df = pd.concat(eval_frames)\n",
    "mean_train_df = train_df.groupby(train_df.index).mean()\n",
    "std_train_df = train_df.groupby(train_df.index).std()\n",
    "mean_eval_df = eval_df.groupby(eval_df.index).mean()\n",
    "std_eval_df = eval_df.groupby(eval_df.index).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.keys(), eval_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to show eval mean episode length, failure rate, and success rate\n",
    "# for train we want the action log prob, mean advantage and mean kl divergence\n",
    "fig, ax = plt.subplots(3, 2, figsize=(16, 16), dpi=200)\n",
    "# row0: train metrics; row1: step count; row2: fail/success\n",
    "# best run\n",
    "ax[0, 0].plot(best_train[\"collected_frames\"], best_train[\"train/mean_action_sample_log_prob\"], label=\"Best\", color=\"red\")\n",
    "ax[0, 1].plot(best_train[\"collected_frames\"], best_train[\"train/mean_advantage\"], label=\"Best\", color=\"red\")\n",
    "ax[1, 0].plot(best_eval[\"collected_frames\"], best_eval[\"eval/mean_step_count\"], label=\"Best\", color=\"red\")\n",
    "ax[1, 1].plot(best_eval[\"collected_frames\"], best_eval[\"eval/max_step_count\"], label=\"Best\", color=\"red\")\n",
    "ax[2, 0].plot(best_eval[\"collected_frames\"], best_eval[\"eval/pct_failed\"], label=\"Best\", color=\"red\")\n",
    "ax[2, 1].plot(best_eval[\"collected_frames\"], best_eval[\"eval/pct_succeeded\"], label=\"Best\", color=\"red\")\n",
    "# plot train data\n",
    "ax[0, 0].plot(mean_train_df[\"collected_frames\"], mean_train_df[\"train/mean_action_sample_log_prob\"], label=\"Average\")\n",
    "ax[0, 0].fill_between(\n",
    "    mean_train_df[\"collected_frames\"],\n",
    "    mean_train_df[\"train/mean_action_sample_log_prob\"] - std_train_df[\"train/mean_action_sample_log_prob\"],\n",
    "    mean_train_df[\"train/mean_action_sample_log_prob\"] + std_train_df[\"train/mean_action_sample_log_prob\"],\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax[0, 0].set_title(\"Train Action Log Probability\", fontsize=28, pad=12)\n",
    "ax[0, 0].set_xlabel(\"\")\n",
    "ax[0, 0].set_ylabel(\"\")\n",
    "ax[0, 1].plot(mean_train_df[\"collected_frames\"], mean_train_df[\"train/mean_advantage\"], label=\"Average\")\n",
    "ax[0, 1].fill_between(\n",
    "    mean_train_df[\"collected_frames\"],\n",
    "    mean_train_df[\"train/mean_advantage\"] - std_train_df[\"train/mean_advantage\"],\n",
    "    mean_train_df[\"train/mean_advantage\"] + std_train_df[\"train/mean_advantage\"],\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax[0, 1].set_title(\"Train Mean Advantage\", fontsize=28, pad=12)\n",
    "ax[0, 1].set_xlabel(\"\")\n",
    "ax[0, 1].set_ylabel(\"\")\n",
    "# plot eval step-count\n",
    "ax[1, 0].plot(mean_eval_df[\"collected_frames\"], mean_eval_df[\"eval/mean_step_count\"], label=\"Average\")\n",
    "ax[1, 1].plot(mean_eval_df[\"collected_frames\"], mean_eval_df[\"eval/max_step_count\"], label=\"Average\")\n",
    "ax[1, 0].fill_between(\n",
    "    mean_eval_df[\"collected_frames\"],\n",
    "    mean_eval_df[\"eval/mean_step_count\"] - std_eval_df[\"eval/mean_step_count\"],\n",
    "    mean_eval_df[\"eval/mean_step_count\"] + std_eval_df[\"eval/mean_step_count\"],\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax[1, 1].fill_between(\n",
    "    mean_eval_df[\"collected_frames\"],\n",
    "    mean_eval_df[\"eval/max_step_count\"] - std_eval_df[\"eval/max_step_count\"],\n",
    "    mean_eval_df[\"eval/max_step_count\"] + std_eval_df[\"eval/max_step_count\"],\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax[1, 0].set_title(\"Mean Eval Step Count\", fontsize=28, pad=12)\n",
    "ax[1, 0].set_xlabel(\"\")\n",
    "ax[1, 0].set_ylabel(\"\")\n",
    "ax[1, 1].set_title(\"Max Eval Step Count\", fontsize=28, pad=12)\n",
    "ax[1, 1].set_xlabel(\"\")\n",
    "ax[1, 1].set_ylabel(\"\")\n",
    "# plot eval failure / success\n",
    "ax[2, 0].plot(mean_eval_df[\"collected_frames\"], mean_eval_df[\"eval/pct_failed\"], label=\"Average\")\n",
    "ax[2, 0].fill_between(\n",
    "    mean_eval_df[\"collected_frames\"],\n",
    "    mean_eval_df[\"eval/pct_failed\"] - std_eval_df[\"eval/pct_failed\"],\n",
    "    mean_eval_df[\"eval/pct_failed\"] + std_eval_df[\"eval/pct_failed\"],\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax[2, 0].set_title(\"Eval Failure Rate\", fontsize=28, pad=12)\n",
    "ax[2, 0].set_xlabel(\"Environment Steps\", fontsize=22, labelpad=15)\n",
    "ax[2, 0].set_ylabel(\"\")\n",
    "ax[2, 1].plot(mean_eval_df[\"collected_frames\"], mean_eval_df[\"eval/pct_succeeded\"], label=\"Average\")\n",
    "ax[2, 1].fill_between(\n",
    "    mean_eval_df[\"collected_frames\"],\n",
    "    mean_eval_df[\"eval/pct_succeeded\"] - std_eval_df[\"eval/pct_succeeded\"],\n",
    "    mean_eval_df[\"eval/pct_succeeded\"] + std_eval_df[\"eval/pct_succeeded\"],\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax[2, 1].set_title(\"Eval Success Rate\", fontsize=28, pad=12)\n",
    "ax[2, 1].set_xlabel(\"Environment Steps\", fontsize=22, labelpad=15)\n",
    "ax[2, 1].set_ylabel(\"\")\n",
    "\n",
    "for row in ax:\n",
    "    for a in row:\n",
    "        a.tick_params(axis=\"both\", which=\"major\", labelsize=18)\n",
    "        a.tick_params(axis=\"both\", which=\"minor\", labelsize=16)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.35)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/Users/davidkorcak/Documents/ctu/bachelors/bachelor_thesis/figures/{run_basename}train_eval.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
