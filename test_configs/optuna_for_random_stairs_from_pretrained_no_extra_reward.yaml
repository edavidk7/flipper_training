study_name: "random_stairs_from_pretrained_no_extra_reward"
num_trials: 200
gpu: 0
metrics_to_optimize:
  - "eval/pct_succeeded" # Maximize
directions:
  - "maximize"
optuna_keys:
  - "policy_opts.actor_optimizer_opts.lr"
  - "policy_opts.value_optimizer_opts.lr"
  - "reward_opts.goal_reached_reward"
  - "reward_opts.failed_reward"
  - "reward_opts.potential_coef"
  - "reward_opts.step_penalty"
  - "scheduler_opts.end_factor"
optuna_types:
  - "float"
  - "float"
  - "float"
  - "float"
  - "float"
  - "float"
  - "float"
optuna_values:
  - [0.0001, 0.0005]
  - [0.0005, 0.003]
  - [5.0, 10.0]
  - [-10.0, -5.0]
  - [20.0, 70.0]
  - [-0.5, -0.2]
  - [0.01, 1.0]
train_config_overrides:
  use_wandb: false
  eval_repeats_after_training: 20
